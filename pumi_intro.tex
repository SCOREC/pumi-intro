\documentclass{article}
\usepackage{hyperref}
\usepackage{listings}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  keepspaces=true,
}

\author{Dan Ibanez}
\title{An Introduction to the PUMI libraries}

\begin{document}

\maketitle

\begin{abstract}
The Parallel Unstructured Mesh Infrastructure (PUMI) is
a set of C and C++ libraries that implement data
structures to represent CAD models and parallel
finite element meshes, and provide functions
for querying and modifying parallel meshes.
PUMI supports a range of real-world projects
which make use of parallel tetrahedral and
mixed meshes.
\end{abstract}

\section{Overview}
PUMI is composed of component libraries, each of
them serving a particular purpose.
The four that all users are likely to deal with
are listed below:

\begin{enumerate}
\item PCU - Communication and parallel coordination
\item APF - User-level mesh and field interface
\item MDS - Underlying mesh implementation of choice
\item GMI - Interfaces with CAD models
\end{enumerate}

There are other components in PUMI, which provide
state-of-the-art functionality for operations like
mesh adaptation and load balance.

All the source code for PUMI is contained in one
repository and compiled as one.
The repository can be found at:

\url{https://github.com/SCOREC/core}

The code is written entirely in C and C++, which
gives it a decent compromise between high performance
and user-friendly abstraction.
More information about the C++ language can be found at:

\url{http://www.cplusplus.com/doc/tutorial/}

These libraries provide header files with structures
and functions for users.
Documentation for all these user-level structures and functions
is provided here:

\url{http://scorec.rpi.edu/~dibanez/core/index.html}

\section{PCU}

The Parallel Control Utility (PCU) library is built
on top of a Message Passing Interface (MPI) implementation,
and is meant to be a higher level interface that people
can use instead of MPI itself.

MPI is the standard system for building massively parallel
programs to run on supercomputers, which all consist
at some level of separate computers connected by a
network which transmits messages between them.
Although it is not necessary to know MPI in order to use
PCU, learning MPI is a recommended starting point.
A decent introduction to MPI can be found here:

\url{ftp://math.usfca.edu/pub/MPI/mpi.guide.ps}

PCU was built on the notion that scalable parallel
programs often use only the following features of MPI:

\begin{enumerate}
\item Basic information like \texttt{MPI\_Comm\_size} and
\texttt{MPI\_Comm\_rank}
\item Collectives like \texttt{MPI\_Reduce} and \texttt{MPI\_Bcast}
\item \label{it:nonblock} More complex communications implemented with variants of
\texttt{MPI\_Isend} and \texttt{MPI\_Irecv}
\end{enumerate}

In particular, PCU implements an efficient algorithm to solve a complex
termination-detection problem and provides an interface that
so far has been able to replace all hand-coded algorithms
of the kind described in Item \ref{it:nonblock} above.

Before we describe complex communication, lets begin with an example
of simple parallel functionality:

\lstinputlisting{pcu1.c}

This program should be compiled and run as a parallel MPI job.
It will print the number of MPI processes in the job, a greeting
message from each of them, and the sum of the integers from 1 to $n$,
where $n$ is the number of processes in the job. 
The output will be a bit out of order, which is a fundamental issue
with outputting text from a parallel job.

Since PCU uses MPI, MPI must be initialized and finalized around
PCU, which has its own initialization and finalization calls.
\texttt{PCU\_Add\_Ints} preforms an all-reduce operation using
an array of integers as the input and output.
In this case, the array is just one integer, $i$, which starts
out as the process rank plus one and is overwritten with the sum
of all such values across the job.

Now lets take a look at the ``phased" communication interface of PCU.
The general idea is that all processes participate in a ``phase",
during which each process sends out messages to other processes.
PCU takes care of delivering messages such that by the end of
the phase all processes have received the messages sent to them.
The following program exchanges an integer message between two
processes (it should only be run as a two-process job):

\lstinputlisting{pcu2.c}

A phase begins when all processes call \texttt{PCU\_Comm\_Begin}.
After that, each process may call \texttt{PCU\_Comm\_Pack} or
the more convenient \texttt{PCU\_COMM\_PACK} macro to pack
data to be sent to some destination.
When all packing is over, a process should call \texttt{PCU\_Comm\_Send}
and enter a loop based on \texttt{PCU\_Comm\_Receive}.
Inside this loop, it should unpack the stream of incoming data.
\texttt{PCU\_Comm\_Sender} will tell where the current data is coming
from; all data from the same source arrives together in the
order it was sent.

\section{APF}

The APF library is the one which users should interact with the
majority of the time.
APF is an abstract interface which allows users to query and manipulate
meshes and fields on meshes.
However, since it is abstract, users will inevitably need to
interact a little with the concrete implementations behind it,
if only at the beginning of the program, i.e. to create the mesh.

\section{MDS}

MDS is the library which handles the concrete mesh structure which
users interact with through APF.
The header file \texttt{apfMDS.h} provides the few functions
which are not part of the main abstract APF interface.
Probably the first used function will be \texttt{apf::loadMdsMesh}:

\begin{lstlisting}
  apf::Mesh2* mesh = apf::loadMdsMesh("model.dmg", "mesh.smb");
\end{lstlisting}

This function will read a CAD model file and mesh files into
the data structure referenced by the variable called \texttt{mesh}.
See Section \ref{sec:gmi} for more information about loading
CAD model files.

As for the mesh files, there is one file per part, where a
part is the subset of the mesh stored on one process.
So, a two-process mesh would have files named \texttt{mesh0.smb}
and \texttt{mesh1.smb}.
As a special case, a single-process mesh just has one file
called \texttt{mesh0.smb}.
The part number at the end of the name is inserted automatically,
so calling the function with ``\texttt{mesh.smb}" in the code
results in \texttt{mesh0.smb} being read into process 0, and so
on for other processes.

\section{GMI}
\label{sec:gmi}

GMI is the library which bridges concrete CAD model structures
to a mesh that users interact with mainly through APF, although
for advanced modeling operations direct calls to GMI may be necessary.
Usually, though, users are concerned only with loading CAD model
files.
There are many kinds of CAD model files, so GMI requires that users
``register" readers for the formats they expect to read.
The simple format is the ``mesh model" format whose files end in
\texttt{.dmg} and contain just enough information to maintain
the relationship between the mesh and CAD model.
To register the mesh model reader, just include \texttt{gmi\_mesh.h}
and call the only function in that file:

\begin{lstlisting}
  gmi_register_mesh();
\end{lstlisting}

Do this before trying to read any mesh model files.

\appendix

\section{Paraview}

Paraview is program created by Kitware, Inc. which can visualize meshes
and fields on meshes.
It is the program of choice for viewing meshes created by the PUMI libraries.
APF provides a function \texttt{apf::writeVtkFiles} in the \texttt{apf.h}
header file.
If this code is executed for a mesh distributed over two processes:

\begin{lstlisting}
  apf::writeVtkFiles("output", mesh);
\end{lstlisting}

It would create the files \texttt{output0.vtu}, \texttt{output1.vtu},
and \texttt{output.pvtu}.
Opening the \texttt{output.pvtu} file in Paraview will show users the
mesh.

By default, Paraview will just render the mesh in ``Surface" mode.
Changing this to ``Surface with Edges" will outline each visible element,
actually making the decomposition visible.
Also, the mesh by default is rendered in one ``Solid Color".
There should be other options corresponding to the fields and numberings
that were on this mesh at the time of file writing.
There is usually an ``apf\_part" alternative for files written by APF, which
allows users to see the parallel partitioning of the mesh in color.

\end{document}
