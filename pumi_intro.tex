\documentclass{article}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  keepspaces=true,
}

\author{PUMI Developers}
\title{An Introduction to the PUMI libraries}

\begin{document}

\maketitle

\begin{abstract}
The Parallel Unstructured Mesh Infrastructure (PUMI) is
a set of C and C++ libraries that provide
functions for querying and modifying parallel meshes, and
querying the geometric models they discretize.
PUMI supports a range of real-world projects
which make use of parallel tetrahedral and
mixed meshes.
\end{abstract}

\section{Overview}
PUMI is composed of component libraries, each of
them serving a particular purpose.
The four that all users are likely to deal with
are listed below:

\begin{enumerate}
\item PCU - Communication and parallel coordination
\item APF - Abstract mesh interface and field implementation
\item MDS - Underlying mesh implementation of choice
\item GMI - Interfaces with geometric models
\end{enumerate}

There are other components in PUMI, which provide
state-of-the-art functionality for operations like
mesh adaptation and load balance.

All the source code for PUMI is contained in one
repository and compiled as one.
The repository can be found at:

\url{https://github.com/SCOREC/core}

The code is written entirely in C and C++, which
gives it a decent compromise between high performance
and user-friendly abstraction.
More information about the C++ language can be found at:

\url{http://www.cplusplus.com/doc/tutorial/}

Each library provides a header file with structures
and functions for users.
Documentation for all these low-level structures and
functions is provided here:

\url{http://www.scorec.rpi.edu/~seol/scorec/doxygen}

New user's should access these structures and functions through the
\href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}
{\texttt{pumi.h}} header file.
Documentation is provided here:

\url{http://scorec.rpi.edu/pumi/PUMI.pdf}

\section{PCU}
\label{sec:pcu}

The Parallel Control Utility (PCU) library is built
on top of a Message Passing Interface (MPI) implementation,
and is meant to be a higher level interface that people
can use instead of MPI itself.

MPI is the standard system for building massively parallel
programs to run on supercomputers, which all consist
at some level of separate computers connected by a
network which transmits messages between them.
Although it is not necessary to know MPI in order to use
PCU, learning MPI is a recommended starting point.
A decent introduction to MPI can be found here:

\url{ftp://math.usfca.edu/pub/MPI/mpi.guide.ps}

PCU was built on the notion that scalable parallel
programs often use only the following features of MPI:

\begin{enumerate}
\item Basic information like
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Comm_size.html}{\texttt{MPI\_Comm\_size}}
and
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Comm_rank.html}{\texttt{MPI\_Comm\_rank}}
\item Collectives like
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Reduce.html}{\texttt{MPI\_Reduce}}
and
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Bcast.html}{\texttt{MPI\_Bcast}}
\item \label{it:nonblock} More complex communications implemented with variants of
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Isend.html}{\texttt{MPI\_Isend}}
and
\href{http://www.mpich.org/static/docs/v3.1/www3/MPI_Irecv.html}{\texttt{MPI\_Irecv}}
\end{enumerate}

In particular, PCU implements an efficient algorithm to solve a complex
termination-detection problem and provides an interface that
so far has been able to replace all hand-coded algorithms
of the kind described in Item \ref{it:nonblock} above.

Before we describe complex communication, lets begin with an example
of simple parallel functionality:

\lstinputlisting{pcu1.c}

This program should be compiled and run as a parallel MPI job.
It will print the number of MPI processes in the job, a greeting
message from each of them, and the sum of the integers from 1 to $n$,
where $n$ is the number of processes in the job.
The output will be a bit out of order, which is a fundamental issue
with outputting text from a parallel job.

Since PCU uses MPI, MPI must be initialized and finalized around
PCU, which has its own initialization and finalization calls.
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#abf86ddf22cc114fd2bd3f054a067c225}{\texttt{PCU\_Add\_Ints}}
performs an all-reduce operation using
an array of integers as the input and output.
In this case, the array is just one integer, $i$, which starts
out as the process rank plus one and is overwritten with the sum
of all such values across the job.

Now lets take a look at the ``phased" communication interface of PCU.
The general idea is that all processes participate in a ``phase",
during which each process sends out messages to other processes.
PCU takes care of delivering messages such that by the end of
the phase all processes have received the messages sent to them.
The following program exchanges an integer message between two
processes (it should only be run as a two-process job):

\lstinputlisting{pcu2.c}

A phase begins when all processes call
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#aa1821bf79d880c38cdd91515751799ac}{\texttt{PCU\_Comm\_Begin}}
.
After that, each process may call
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#afd8a6600d960129089c45fd49c1b2311}{\texttt{PCU\_Comm\_Pack}}
or the more convenient
\texttt{PCU\_COMM\_PACK}
macro to pack data to be sent to some destination.
When all packing is over, a process should call
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#a263061f00174fc7a004dcb198778006c}{\texttt{PCU\_Comm\_Send}}
and enter a loop based on
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#ad02bc960bcfa8e2d6b09458dca38bf53}{\texttt{PCU\_Comm\_Receive}}
.
Inside this loop, it should unpack the stream of incoming data.
\href{http://scorec.rpi.edu/~dibanez/core/pcu_8c.html#ac4577ded2ec61de4b4141e3353aac440}{\texttt{PCU\_Comm\_Sender}}
will tell where the current data is coming
from; all data from the same source arrives together in the
order it was sent.

The functions \texttt{PCU$\_$Comm$\_$Init}, \texttt{PCU$\_$Comm$\_$Free},
\texttt{PCU$\_$Comm$\_$Peers}, \texttt{PCU$\_$Comm$\_$Self}, \texttt{PCU$\_$Comm$\_$Barrier} are respectively
equivalent to \texttt{pumi$\_$start}, \texttt{pumi$\_$finalize},
\texttt{pumi$\_$size}, \texttt{pumi$\_$rank} and \texttt{pumi$\_$sync} in \texttt{pumi.h}.

\section{Mesh}
\label{sec:mds}

MDS is the library which handles the concrete mesh structure.
The header file
\href{https://github.com/SCOREC/core/blob/master/mds/apfMDS.h}{\texttt{apfMDS.h}}
provides the few functions which are not part of the
\href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}{\texttt{pumi.h}}
interface.
Probably the first used function will be \texttt{pumi$\_$mesh$\_$load}.

\begin{lstlisting}
  int num_parts = pumi_size();
  pGeom g = pumi_geom_load("model.dmg");
  pMesh mesh = pumi_mesh_load(g, "mesh.smb", num_parts);
\end{lstlisting}

This function will read a geometric model file and mesh files into
the data structure referenced by the variable called \texttt{g} and \texttt{mesh}.
See Section \ref{sec:gmi} for more information about loading
geometric model files. 

The second argument of \emph{pumi$\_$mesh$\_$load} is the mesh file name.
As for the mesh files, if the mesh is partitioned, there is one file per part, where a
part is the subset of the mesh stored on one process.
So, a two-part mesh would have files named \texttt{mesh0.smb}
and \texttt{mesh1.smb}, and a serial (single-part) mesh just has one file
called \texttt{mesh0.smb}.
The part number at the end of the name is inserted automatically,
so calling the function with ``\texttt{mesh.smb}" in the code
results in \texttt{mesh0.smb} being read into process 0, and so
on for other processes.

The third argument of \emph{pumi$\_$mesh$\_$load} is the number of mesh files.
Suppose \emph{pumi$\_$mesh$\_$load} is called on $p$ processes ($p$$>$1) and the number of mesh file is $1$ (in other words, you have only \texttt{mesh0.smb}). In this case, the serial mesh is loaded onto the master process (process $0$) and partitioned to $p$ processes. 

If you load the $p$-part mesh onto $p$ processes, the third argument is $p$, of which value is \emph{pumi$\_$size()}

At the end of your program, you should release the computer
memory that was used to store the mesh and geometric model.

\begin{lstlisting}
pumi_mesh_delete(mesh);
\end{lstlisting}

In some cases, you may want to construct your own small mesh.
The easiest way to do this is to make an empty MDS mesh
on a null geometry.
See Section \ref{sec:gmi} for info on null geometry.

\begin{lstlisting}
pMesh mesh = pumi_mesh_create(pumi_geom_load(NULL, "null"), 3, false);
\end{lstlisting}

The second argument to \texttt{pumi$\_$mesh$\_$create}
specifies the dimensionality of the mesh; either 2D or 3D.
The final argument of \texttt{pumi$\_$mesh$\_$create} secifies
whether periodic associations exist between entities, this is
almost always false.

Once you have constructed your mesh as described in Section \ref{sec:gen},
you may want to create a simple geometry around it using
this special function:

% What does this have to do with model creation?
\begin{lstlisting}
pumi_mesh_freeze(mesh);
\end{lstlisting}

\section{Geometric Model}
\label{sec:gmi}

GMI is the library which bridges geometric model structures
to a mesh that users interact with.
Interactions are mainly through
\href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}{\texttt{pumi.h}},
but for advanced modeling operations direct calls to GMI may be necessary.
Usually, though, users are concerned only with loading geometric model files.
As there are many kinds of geometric models, the user has to specify the
``model type" along with geometric model files.
In case of PUMI API, the function \emph{pumi$\_$geom$\_$load} performs both
model type set-up and model loading as the second argument is a character
string specifying the model type (``null" for no model, ``mesh" for
mesh-driven model, and ``analytic" for analytic model).
% What about PARASOLID and ACIS models?
The simple format is the ``mesh model" format whose files end in \texttt{.dmg}
and contain just enough information to maintain the relationship between the
mesh and geometric model.
To load a mesh model,

\begin{lstlisting}
  pumi_geom_load(/path/to/your/mesh/model.dmg, "mesh");
\end{lstlisting}

In some cases, users do not really care about the geometric model at
all.
For such cases, there is a ``null" geometric model that can be used,
which just mimicks the minimal necessary behavior to support
the rest of the code.
You can get a null model as follows:

\begin{lstlisting}
  pumi_geom_load(NULL, "null");
\end{lstlisting}

\section{APF}

APF is a library to provide an abstract interface to various mesh
implementations and fields on meshes.
Part of its structures and functionalities are accessible through
\href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}{\texttt{pumi.h}}.
However, since it is abstract, users may need to interact a little with the
concrete implementations behind it.
When the underlying objects need to be accessed it is important to understand
that a
\href{http://scorec.rpi.edu/~dibanez/core/classapf_1_1Mesh.html}{\texttt{apf::Mesh}}
object can be queried but not modified, while a
\href{http://scorec.rpi.edu/~dibanez/core/classapf_1_1Mesh2.html}{\texttt{apf::Mesh2}}
object may be queried and modified.
In \href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}{\texttt{pumi.h}},
the data type to a modifiable mesh instance (pointer to a mesh data structure)
is \texttt{pMesh}~.

\subsection{Entities}

These functions will refer to mesh entities in the
form of \texttt{pMeshEnt} variable.
One of the most fundamental pieces of information you can get
out of an \texttt{pMeshEnt} variable is what kind of
entity it is.
The kind is encoded in a C++ enumeration value,
\begin{lstlisting}
enum PUMI_EntTopology {
  PUMI_VERTEX,    // 0
  PUMI_EDGE,      // 1
  PUMI_TRIANGLE,  // 2
  PUMI_QUAD,      // 3
  PUMI_TET,       // 4
  PUMI_HEX,       // 5
  PUMI_PRISM,     // 6
  PUMI_PYRAMID    // 7
);
\end{lstlisting}

and obtained using \emph{pumi$\_$ment$\_$getTopo}.

\begin{lstlisting}
pMeshEnt e = ...;
int topology = pumi_ment_getTopo(e);
if (topology == PUMI_QUAD)
   std::cout << "this is a quad\n";
\end{lstlisting}

\subsection{Numbering}
\label{sec:num}

First-time users may want a way to identify mesh entities for
printing to application output (i.e. via \texttt{printf} and friends)
and/or for viewing in Paraview (see Appendix \ref{sec:paraview}).
A general way to do this is using a \texttt{Numbering} object.
To number the regions, one can do the following:

\begin{lstlisting}
pNumbering numbers = pumi_numbering_createOwned(
    mesh, "my_numbers", 3);
\end{lstlisting}

The second argument is a name of your choice, unique to this numbering object.
The last argument says to number three-dimensional entities, i.e. regions.

Due to details of how we communicate with Paraview, there is a
function which is better for numbering vertices than
\texttt{pumi$\_$numbering$\_$createOwned(..., 0)}, which is
% Is this correct? The name seems odd.
{\texttt{pumi$\_$numbering$\_$createOwnedNode}.

After numbering entities, you can call the following to obtain the number of an
entity:

\begin{lstlisting}
pMeshEnt vertex = ...;
int vertex_id = pumi_ment_getNumber(numbers, vertex, 0, 0);
\end{lstlisting}

The last two arguments are used to number high-order fields and
multiple degrees of freedom per node, if you don't use those
advanced features just set them to zero.

In other cases, you may want to assign numbers yourself.
To do that, start by making an empty numbering:

\begin{lstlisting}
pNumbering numbers = pumi_numbering_create(
       mesh, "my_numbers",  pumi_mesh_getShape(mesh), 1);
\end{lstlisting}

The third argument specifies that we are numbering the mesh
nodes and the last argument specifies that there is just one
number per node.
Then you can set the numbers yourself using \texttt{pumi$\_$ment$\_$setNumber}.

Also note that \texttt{Numbering} is a good way to store
any integer value on mesh entities, not necessarily an
ordered numbering.

\subsection{Iteration}

Most operations will require iterating over mesh entities,
which can be done one dimension at a time.
Iteration uses an iterator pointer as follows:

% Is this the pumi equivalent for iterating?
\begin{lstlisting}
pMeshIter it = mesh->begin(1);
pMeshEnt e;
while ((e = mesh->iterate(it))) {
  /* use "e" somehow */
}
mesh->end(it);
\end{lstlisting}

\subsection{Coordinates and Vector3}

You can query and modify the coordinates of mesh nodes.
Using \href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}
{\texttt{pumi.h}} the coordinate information is handled in the form of
an array of three double-precision floating point values.
For example, the following code changes the y-coordinate of vertex {\texttt{v}} and print:

\begin{lstlisting}
#include <iostream>
#include <pumi.h>
double v[3];
pumi_node_getCoord(vertex, 0, v);
v[1] = 0.8;
pumi_node_setCoord(vertex, 0, v);
std::cout << "vertex coord (" << v[0]<<", "<<v[1]<<", "<<v[2]<< ")\n";
\end{lstlisting}

In the low-level implementation, the coordinate information is handled in the form of \texttt{Vector3} 
objects.
You can treat \texttt{Vector3} just like an array, but it is
possible to apply mathematical operators like addition, subtraction,
multiplication by a scalar, etc. to these objects.
There is also a C++ stream output operator for these objects, which
means they can be given to C++'s \texttt{std::cout}.

\begin{lstlisting}
#include <iostream>
#include <pumi.h>
Vector3 v1;
pumi_node_getCoordVector(vertex1, 0, v1);
std::cout << "vertex coord "<<v1<<"\n";
Vector3 v2(8.0 / 4 * i, 8.0 / 6 * j, 0);
pumi_node_setCoordVector(vertex2, 0, v2);
// cross product of v1 and v2
double V = pumi_vector3_cross(v1, v2);
\end{lstlisting}

The second argument to set/get coordination information is intended to handle
high order fields where there is more than one node
per mesh entity.
For first-order mesh entities, set this to zero.
For quadratic meshes, these functions will operate on edges as well as vertices.

Speaking of quadratic meshes, you can convert a linear mesh
to a quadratic mesh using the following call:

\begin{lstlisting}
pumi_mesh_setShape(mesh, pumi_shape_getLagrange(2));
\end{lstlisting}

\subsection{Adjacency}

Most finite element algorithms require adjacency information.
The most important information is downward adjacency, for
example, getting the vertices of an element.

\begin{lstlisting}
pMeshEnt element = ...;
std::vector<pMeshEnt> v;
pumi_ment_getAdj(element, 0, v);
size_t numVertices = v.size();
pMeshEnt lastVertex = v[numVertices - 1];
\end{lstlisting}

The second argument to {\texttt{pumi\_ment\_getAdj}}
is the target dimension, in this case 0 meaning vertices.

The inverse of downward adjacency is upward adjacency,
for example, what elements are around a vertex.

\begin{lstlisting}
pMeshEnt vertex = ...;
std::vector<pMeshEnt> e;
pumi_ment_getAdj(vertex, pumi_mesh_getDim(m), e);
pMeshEnt element = e[e.size() - 1 ];
\end{lstlisting}

Below is a full example program demonstrating file reading,
adjacency queries, and coordinate output using PUMI API.
It will print one line for each element in the mesh,
containing its vertex coordinates.

\lstinputlisting{pumi1.cc}

\subsection{Construction}
\label{sec:gen}

Finally, you may want to construct your own mesh at
some point.
This is usually best separated into two steps:
\begin{enumerate}
\item create the vertices at the right points.
\item create the elements based on their vertices
\end{enumerate}

Prior to these steps, refer to Section \ref{sec:mds} for
how to create an empty mesh.
Then use \texttt{pumi$\_$mesh$\_$createVtx} to create a vertex.
Its arguments are mesh instance, the geometric classification, and \emph{xyz}
coordinates.
The geometric classification can be left as \emph{NULL} if the model derivation
described in \ref{sec:mds} is used after construction.

It is advisable to store the vertex pointers in some sort
of structure to prepare them for the second step,
which is to create elements using \texttt{pumi$\_$mesh$\_$createElem}.
Note that \texttt{pumi$\_$mesh$\_$createElem} is given an array
of vertices, and the order of those vertices is important.
The documentation for
% Is there a pumi equivalent for this?
\href{http://scorec.rpi.edu/~dibanez/core/classapf_1_1Mesh.html#ae9af2075129ffd4553092049d85b276b}{\texttt{apf::Mesh::getDownward}}
shows pictures of the expected ordering for vertices
in this array, for each element type.

Finally, when mesh construction is over, the function
% We previously talked about removing the apf 'freeze' - does this call apf
% freeze or apf complete?
\texttt{pumi$\_$mesh$\_$freeze} has to be called to finalize the mesh data
structure.
After \texttt{pumi$\_$mesh$\_$freeze} is called, it is possible to run
a stringent verification on the mesh structure itself,
to make sure no mistakes were made during construction.
This is done using \texttt{pumi$\_$mesh$\_$verify}.

Here is a full example code which constructs a one-tet
mesh and writes Paraview files.

\lstinputlisting{pumi2.cc}

\subsection{Classification}

When the mesh is classified onto a geometric model of some sort, we
can query that relationship.
In \href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}
{\texttt{pumi.h}}, the data type to a geometric model instance (a pointer to
geometric model data structure) is \texttt{pGeom}.
Given a mesh instance, the function \texttt{pumi$\_$mesh$\_$getGeom} returns
its associated geometric model instance.
The data type to a geometric model entity is {\texttt{pGeomEnt}}~.
\
For many meshing operations, two integers are all the information
we need about a geometric model entity.
First, its dimension (like mesh entities, there are vertices, faces, etc.).
Second, a unique integer ID which sets the entity apart from
all other entities of the same dimension (these ID's are not necessarily
unique across \emph{all} model entities).
Given a geometric model entity, the function
\texttt{pumi$\_$ment$\_$getGeomClas} returns the geometric model entity
instance where it's generated from.

\begin{lstlisting}
pGeom g = pumi_mesh_getGeom(mesh);
pMeshEnt e = ...;
pGeomEnt ge = pumi_ment_getGeomClas(e);
int dimension = pumi_gent_getDim(ge);
int id = pumi_gent_getID(ge);
assert(pumi_geom_getNumEnt(g, dimension));
\end{lstlisting}

\subsection{Parallel Meshes}

Once you are dealing with parallel, or partitioned, meshes,
it will be important to get information about how the
mesh is partitioned.
In PUMI, we partition meshes by elements.
That is, each element will exist in exactly one part.
All mesh entities which bound that element will also exist on
the same part.
Because mesh entities may bound multiple elements, they may
exist on multiple parts.
This is where remote copies come in.
Each mesh entity stores information about the other parts
on which it exists, including pointers to its other copies.

\begin{lstlisting}
pMeshEnt vertex = ...;
Copies remotes;
pumi_ment_getAllRmt(vertex, remotes);
for (pCopyIter it = remotes.begin();
     it != remotes.end(); ++it)
  std::cout << "shared with part " << it->first << '\n;
\end{lstlisting}

\texttt{Copies} is a
\href{http://www.cplusplus.com/reference/map/map/}{\texttt{std::map}}
whose keys are part numbers and whose
values are pointers to copies on those parts.
We will return later to the issue of these pointers and
why they are there.

Before that, a few more basics.
% replace with PUMI version?
First, recall from Section \ref{sec:pcu} that \texttt{pumi\_rank}
gives you the process rank.
This is identical to the part number, so remember that the two
can be used interchangeably.
Second, given a mesh entity with copies, the PUMI system decides
on one of the copies to designate as the owner.
You can check whether the local copy is the owner:

\begin{lstlisting}
if (pumi_ment_isOwned(vertex))
  std::cout << "yes\n";
\end{lstlisting}

Now we can put those concepts all together and write a program
which sets up a numbering by first assigning numbers to
the vertices which it owns, and then communicating those
numbers to the non-owned copies so that all copies
of the same vertex have the same number.
To do this, we need to use the pointer values in \texttt{Copies}.
This gives us \texttt{pMeshEnt} values which are usable
on the destination part to refer to the copy.

\lstinputlisting{pumi3.cc}

\subsection{Migration}

An additional topic of interest when dealing with parallel
meshes is migration.
In this case, that means the ability to send elements
from one part to another.
Since each part is controlled by a separate process,
the process collects a list of elements which it
wants to send and the destination parts to which
it wants to send them.
This ``plan" is stored in an
\href{http://scorec.rpi.edu/~dibanez/core/classapf_1_1Migration.html}{\texttt{Migration}}
object.
This object should be created like this:

% There is no PUMI equivalent for this?
\begin{lstlisting}
Migration* plan = new Migration(mesh);
\end{lstlisting}

Once the migration plan of elements to send from
the local process is complete, it is given to the
\texttt{pumi$\_$mesh$\_$migrate} function.
All processes should call this function at the
same time, even if they have nothing to send.
This function will delete the plan, so users
do not have to delete it themselves.

\appendix

\section{Paraview}
\label{sec:paraview}

Paraview is program created by Kitware, Inc. which can visualize meshes
and fields on meshes.
It is the program of choice for viewing meshes created by the PUMI libraries.
PUMI provides the function \texttt{pumi$\_$mesh$\_$write}
in the \href{https://github.com/SCOREC/core/blob/master/pumi/pumi.h}
{\texttt{pumi.h}} header file.
If this code is executed for a mesh distributed over two processes:

\begin{lstlisting}
  pumi_mesh_write(mesh, "output", "vtk");
\end{lstlisting}

It would create the folder \texttt{output} and files \texttt{0.vtu}, \texttt{1.vtu},
and \texttt{output.pvtu}.
Opening the \texttt{output.pvtu} file in Paraview will show users the
mesh.

By default, Paraview will just render the mesh in ``Surface" mode.
Changing this to ``Surface with Edges" will outline each visible element,
actually making the decomposition visible.

Also, the mesh by default is rendered in one ``Solid Color".
There should be other options corresponding to the fields and numberings
that were on this mesh at the time of file writing.
There is usually an ``apf\_part" alternative for files written by PUMI, which
allows users to see the parallel partitioning of the mesh in color.

When vertices are numbered, it may be useful to display their numbers.
See Section \ref{sec:num} for information on creating numberings.
Right above the mesh viewing area there is a button to select nodes,
you may also press the ``D" key.

\begin{center}
\includegraphics[width=0.05\textwidth]{select_nodes.png}
\end{center}

Click and drag to select all the nodes you want to display.
Then go to \texttt{View->Selection Display Inspector} in the menu and click on
the Point Labels options.
There you can choose what to display.
If you used \texttt{Numbering} properly, there should be an option
with the same name that you gave to the numbering.
Note that in some later versions of Paraview, there is a bug which
displays all values as floating point numbers by default.
If you are trying to show \texttt{Numbering} values, you may
see strange scientific notation instead.
Click the following icon in the Selection Display Inspector:

\begin{center}
\includegraphics[width=0.05\textwidth]{gear.png}
\end{center}

There you will find a format string option, which you can change
to ``\texttt{\%d}" in order to show integers.

\end{document}
